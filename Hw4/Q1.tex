First, we sample $k$ times from the underlying distribution of size $m>m(\frac{\epsilon}{2})$ and use A to find k $\delta_0$ weak-confidence hypotheses (denoted by $\hat{H}_k$). Denoting the event:
\begin{equation*}
    E = \{\exists h_{S_i}^A \in \hat{H}_k s.t. err(h_{S_i}^A) < \underset{h\in \mathcal{H}}{min} err(h) + \frac{\epsilon}{2}\}
\end{equation*}

then:
\begin{equation*}
    \begin{split}
        P(\bar{E}) &= P(\{\forall i\in [k], \; h_{S_i}^A \in \hat{H}_k,  err(h_{S_i}^A) > \underset{h\in \mathcal{H}}{min} err(h) + \epsilon \}) = \prod_{i=1}^k P(err(h_{S_i}^A) \\
        &> \underset{h\in \mathcal{H}}{min} err(h) + \epsilon ) \leq \delta_0^k \overset{!}{<} \frac{\delta}{2} \\
        k &> \frac{log(\delta/2)}{log(\delta_0)}
    \end{split}
\end{equation*}

In other words, if we use A $k \geq \frac{log(\delta/2)}{log(\delta_0)}$ times, we end up with a family of k weak-confidence hypotheses out of which at least one is more than $\frac{\epsilon}{2}$ accurate w.p. at least $1-\frac{\delta}{2}$.

What's left is to design a process to find which of the k hypotheses is the desired one. For that, we sample yet again from D, this time with a size $m > m(\frac{\epsilon}{2}, \frac{\delta}{2}) = O\left(\frac{4k log\frac{2}{\delta}}{\epsilon^2}\right)$, and use it to detect the desired hypothesis by applying a simple ERM rule over the set $\hat{H}$. This is guaranteed to work since every finite hypothesis class is agnostic PAC learnable with sample complexity defined by the desired accuracy, probability and the VC-dimension of the hypotheses class (which in the case of a finite hypotheses class is upper bounded by the log of it's size). Thus, w.p. at least $1-\frac{\delta}{2}$ we are guaranteed to find:
\begin{equation*}
    err(h) \leq \underset{h_S^A \in \hat{H}_k}{min} err(h_S^A) + \frac{\epsilon}{2}
\end{equation*}

Thus, using the union bound, and a total sample of size $m > O(km_\mathcal{H}(\frac{\epsilon}{2}) + \frac{4k log\frac{2}{\delta}}{\epsilon^2})$, we get w.p. at least $1-\delta$:
\begin{equation*}
    err(h) \leq \underset{h_S^A \in \hat{H}_k}{min} err(h_S^A) + \frac{\epsilon}{2} \leq \underset{h\in \mathcal{H}}{min} err(h) + \frac{\epsilon}{2}
\end{equation*}
